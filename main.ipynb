{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import typing\n",
    "from datetime import datetime\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Course\n",
      "Date               \n",
      "2015-01-01  56.2376\n",
      "2015-01-13  62.7363\n",
      "2015-01-14  64.8425\n",
      "2015-01-15  66.0983\n",
      "2015-01-16  64.8337\n",
      "...             ...\n",
      "2024-02-06  91.2434\n",
      "2024-02-07  90.6842\n",
      "2024-02-08  91.1514\n",
      "2024-02-09  91.2561\n",
      "2024-02-10  90.8901\n",
      "\n",
      "[2237 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.columns = [\"Date\", \"Course\"]\n",
    "df = df.set_index('Date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "if not df.index.is_monotonic_increasing:\n",
    "    df = df.sort_index()\n",
    "df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Course     lag1     lag2     lag3     lag4     lag5     lag6  \\\n",
      "Date                                                                        \n",
      "2015-06-06  56.2463  54.9908  53.0590  53.4413  52.8213  52.9716  52.2907   \n",
      "2015-06-09  56.0435  56.2463  54.9908  53.0590  53.4413  52.8213  52.9716   \n",
      "2015-06-10  55.9100  56.0435  56.2463  54.9908  53.0590  53.4413  52.8213   \n",
      "2015-06-11  54.8219  55.9100  56.0435  56.2463  54.9908  53.0590  53.4413   \n",
      "2015-06-12  54.5285  54.8219  55.9100  56.0435  56.2463  54.9908  53.0590   \n",
      "...             ...      ...      ...      ...      ...      ...      ...   \n",
      "2024-02-06  91.2434  90.6626  90.2299  89.6678  89.2887  89.6090  89.5159   \n",
      "2024-02-07  90.6842  91.2434  90.6626  90.2299  89.6678  89.2887  89.6090   \n",
      "2024-02-08  91.1514  90.6842  91.2434  90.6626  90.2299  89.6678  89.2887   \n",
      "2024-02-09  91.2561  91.1514  90.6842  91.2434  90.6626  90.2299  89.6678   \n",
      "2024-02-10  90.8901  91.2561  91.1514  90.6842  91.2434  90.6626  90.2299   \n",
      "\n",
      "               lag7     lag8     lag9  ...    lag91    lag92    lag93  \\\n",
      "Date                                   ...                              \n",
      "2015-06-06  51.0178  50.3223  49.8613  ...  65.4000  65.5558  64.9862   \n",
      "2015-06-09  52.2907  51.0178  50.3223  ...  63.3930  65.4000  65.5558   \n",
      "2015-06-10  52.9716  52.2907  51.0178  ...  65.5937  63.3930  65.4000   \n",
      "2015-06-11  52.8213  52.9716  52.2907  ...  67.8153  65.5937  63.3930   \n",
      "2015-06-12  53.4413  52.8213  52.9716  ...  67.1506  67.8153  65.5937   \n",
      "...             ...      ...      ...  ...      ...      ...      ...   \n",
      "2024-02-06  88.6562  88.2829  87.9199  ...  96.6172  96.2236  96.6472   \n",
      "2024-02-07  89.5159  88.6562  88.2829  ...  96.0762  96.6172  96.2236   \n",
      "2024-02-08  89.6090  89.5159  88.6562  ...  96.0419  96.0762  96.6172   \n",
      "2024-02-09  89.2887  89.6090  89.5159  ...  96.1456  96.0419  96.0762   \n",
      "2024-02-10  89.6678  89.2887  89.6090  ...  96.2378  96.1456  96.0419   \n",
      "\n",
      "              lag94    lag95    lag96    lag97    lag98    lag99   lag100  \n",
      "Date                                                                       \n",
      "2015-06-06  64.9732  65.1738  64.8337  66.0983  64.8425  62.7363  56.2376  \n",
      "2015-06-09  64.9862  64.9732  65.1738  64.8337  66.0983  64.8425  62.7363  \n",
      "2015-06-10  65.5558  64.9862  64.9732  65.1738  64.8337  66.0983  64.8425  \n",
      "2015-06-11  65.4000  65.5558  64.9862  64.9732  65.1738  64.8337  66.0983  \n",
      "2015-06-12  63.3930  65.4000  65.5558  64.9862  64.9732  65.1738  64.8337  \n",
      "...             ...      ...      ...      ...      ...      ...      ...  \n",
      "2024-02-06  96.6338  96.1609  95.9794  94.7035  96.5083  97.9241  98.1961  \n",
      "2024-02-07  96.6472  96.6338  96.1609  95.9794  94.7035  96.5083  97.9241  \n",
      "2024-02-08  96.2236  96.6472  96.6338  96.1609  95.9794  94.7035  96.5083  \n",
      "2024-02-09  96.6172  96.2236  96.6472  96.6338  96.1609  95.9794  94.7035  \n",
      "2024-02-10  96.0762  96.6172  96.2236  96.6472  96.6338  96.1609  95.9794  \n",
      "\n",
      "[2137 rows x 101 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sk1fix\\AppData\\Local\\Temp\\ipykernel_19608\\1140879964.py:4: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lags(df: DataFrame, n_lags: int) -> DataFrame:\n",
    "    dfc = df.copy()\n",
    "    for i in range(1, n_lags + 1):\n",
    "        dfc[f\"lag{i}\"] = dfc[\"Course\"].shift(i)\n",
    "    dfc = dfc.iloc[n_lags:]\n",
    "    return dfc\n",
    "\n",
    "\n",
    "input_dim = 100\n",
    "\n",
    "df_lags = lags(df, input_dim)\n",
    "print(df_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281\n",
      "428\n",
      "428\n"
     ]
    }
   ],
   "source": [
    "def feature_label_split(df: DataFrame, target_col: str) -> tuple[DataFrame]:\n",
    "    \"\"\"\n",
    "        Separation of validation and training sets\n",
    "    \"\"\"\n",
    "    y = df[[target_col]]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_val_test_split(df: pd.DataFrame, target_col: str, test_ratio: float) -> tuple[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "        Separation of validation and training sets\n",
    "    \"\"\"\n",
    "    val_ratio = test_ratio / (1 - test_ratio)\n",
    "    X, y = feature_label_split(df, target_col)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_ratio, shuffle=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_ratio, shuffle=False)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
    "    df_lags, 'Course', 0.2)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
